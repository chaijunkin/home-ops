---
apiVersion: grafana.integreatly.org/v1beta1
kind: GrafanaAlertRuleGroup
metadata:
  name: fly-app-alerts
  namespace: observability
spec:
  instanceSelector:
    matchLabels:
      grafana.internal/instance: grafana

  folderRef: "external-folder"
  interval: 1m
  name: "Fly App Extended Monitoring"

  rules:
    # === HTTP Alerts ===

    # 1. High 4xx Error Rate
    - uid: fly-app-4xx-rate
      title: "Fly App - High 4xx Error Rate"
      condition: D
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              sum by(app) (
                rate(fly_edge_http_responses_count{status=~"4.*"}[5m])
              )
            refId: A
        - refId: B
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              sum by(app) (
                rate(fly_edge_http_responses_count[5m])
              )
            refId: B
        - refId: C
          datasourceUid: "-100"
          model:
            type: math
            refId: C
            expression: "$A / $B * 100"
        - refId: D
          datasourceUid: "-100"
          model:
            type: threshold
            refId: D
            expression: C
            conditions:
              - evaluator:
                  params: [15]
                  type: gt
      for: 10m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "High 4xx rate for {{ $labels.app }}"
        description: "Client error rate is {{ $values.C.Value | humanizePercentage }}. Check for invalid requests or API changes."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: warning
        alertname: High4xxRate
        job: fly-app
        team: platform
        service: fly-app

    # 2. Edge Response Time Spike
    - uid: fly-app-edge-latency
      title: "Fly App - High Edge Response Time"
      condition: C
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              histogram_quantile(0.95,
                sum by(app, le) (
                  rate(fly_edge_http_response_time_seconds_bucket[5m])
                )
              )
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: reduce
            refId: B
            expression: A
            reducer: last
        - refId: C
          datasourceUid: "-100"
          model:
            type: threshold
            refId: C
            expression: B
            conditions:
              - evaluator:
                  params: [2]
                  type: gt
      for: 5m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "Edge response time elevated for {{ $labels.app }}"
        description: "Edge p95 latency is {{ $values.A.Value }}s. Check CDN and network."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: warning
        alertname: HighEdgeLatency
        job: fly-app
        team: platform
        service: fly-app

    # === TLS/SSL Alerts ===

    # 3. TLS Handshake Errors
    - uid: fly-app-tls-errors
      title: "Fly App - TLS Handshake Errors"
      condition: B
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              sum(increase(fly_edge_tls_handshake_errors[5m])) > 0
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: threshold
            refId: B
            expression: A
            conditions:
              - evaluator:
                  params: [10]
                  type: gt
      for: 5m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "TLS handshake errors detected"
        description: "{{ $values.A.Value }} TLS handshake errors in the last 5 minutes. Check certificate validity."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: high
        alertname: TLSHandshakeErrors
        job: fly-app
        team: platform
        service: fly-app

    # 4. TLS SNI Limit Reached
    - uid: fly-app-sni-limit
      title: "Fly App - TLS SNI Limit Reached"
      condition: B
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              sum(increase(fly_edge_tls_sni_limit_reached_count[5m])) > 0
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: threshold
            refId: B
            expression: A
            conditions:
              - evaluator:
                  params: [0]
                  type: gt
      for: 5m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "TLS SNI concurrency limit reached"
        description: "Server reached TLS SNI limit. Handshakes are being queued."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: warning
        alertname: TLSSNILimit
        job: fly-app
        team: platform
        service: fly-app

    # 5. Slow TLS Handshakes
    - uid: fly-app-slow-tls
      title: "Fly App - Slow TLS Handshakes"
      condition: C
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              histogram_quantile(0.95,
                sum by(le) (
                  rate(fly_edge_tls_handshake_time_seconds_bucket[5m])
                )
              )
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: reduce
            refId: B
            expression: A
            reducer: last
        - refId: C
          datasourceUid: "-100"
          model:
            type: threshold
            refId: C
            expression: B
            conditions:
              - evaluator:
                  params: [1]
                  type: gt
      for: 10m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "TLS handshakes are slow"
        description: "P95 handshake time is {{ $values.A.Value }}s. May impact user experience."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: warning
        alertname: SlowTLSHandshakes
        job: fly-app
        team: platform
        service: fly-app

    # === TCP Connection Alerts ===

    # 6. High Connection Rate
    - uid: fly-app-high-connections
      title: "Fly App - High Connection Rate"
      condition: B
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              sum(rate(fly_edge_tcp_connects_count[5m]))
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: threshold
            refId: B
            expression: A
            conditions:
              - evaluator:
                  params: [1000]
                  type: gt
      for: 5m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "Unusually high connection rate"
        description: "{{ $values.A.Value }}/sec connection rate. Possible traffic spike or DDoS."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: warning
        alertname: HighConnectionRate
        job: fly-app
        team: platform
        service: fly-app

    # 7. Connection Churn (High Disconnect Rate)
    - uid: fly-app-connection-churn
      title: "Fly App - High Connection Churn"
      condition: D
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              sum(rate(fly_app_tcp_disconnects_count[5m]))
            refId: A
        - refId: B
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              sum(rate(fly_app_tcp_connects_count[5m]))
            refId: B
        - refId: C
          datasourceUid: "-100"
          model:
            type: math
            refId: C
            expression: "$A / $B * 100"
        - refId: D
          datasourceUid: "-100"
          model:
            type: threshold
            refId: D
            expression: C
            conditions:
              - evaluator:
                  params: [80]
                  type: gt
      for: 10m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "High connection churn detected"
        description: "{{ $values.C.Value }}% of connections are short-lived. Check app health."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: warning
        alertname: HighConnectionChurn
        job: fly-app
        team: platform
        service: fly-app

    # === Machine/Resource Alerts ===

    # 8. High Load Average
    - uid: fly-app-high-load
      title: "Fly App - High Load Average"
      condition: B
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              max(fly_instance_load_average{minutes="1"})
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: threshold
            refId: B
            expression: A
            conditions:
              - evaluator:
                  params: [4]
                  type: gt
      for: 5m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "High load average on {{ $labels.app }}"
        description: "1-minute load average is {{ $values.A.Value }}. CPU may be saturated."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: warning
        alertname: HighLoadAverage
        job: fly-app
        team: platform
        service: fly-app

    # 9. High Network Transfer
    - uid: fly-app-high-network
      title: "Fly App - High Network Transfer"
      condition: B
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              sum(rate(fly_instance_net_sent_bytes{device="eth0"}[5m])) +
              sum(rate(fly_instance_net_recv_bytes{device="eth0"}[5m]))
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: threshold
            refId: B
            expression: A
            conditions:
              - evaluator:
                  params: [104857600]
                  type: gt
      for: 10m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "High network traffic for {{ $labels.app }}"
        description: "Network transfer is {{ $values.A.Value | humanize1024 }}B/s. Monitor bandwidth costs."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: info
        alertname: HighNetworkTransfer
        job: fly-app
        team: platform
        service: fly-app

    # 10. Low Memory Available
    - uid: fly-app-low-memory
      title: "Fly App - Low Memory Available"
      condition: D
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              avg(fly_instance_memory_mem_available)
            refId: A
        - refId: B
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              avg(fly_instance_memory_mem_total)
            refId: B
        - refId: C
          datasourceUid: "-100"
          model:
            type: math
            refId: C
            expression: "$A / $B * 100"
        - refId: D
          datasourceUid: "-100"
          model:
            type: threshold
            refId: D
            expression: C
            conditions:
              - evaluator:
                  params: [10]
                  type: lt
      for: 5m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "Low available memory on {{ $labels.app }}"
        description: "Only {{ $values.C.Value }}% memory available. Risk of OOM."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: high
        alertname: LowMemoryAvailable
        job: fly-app
        team: infrastructure
        service: fly-app

    # 11. High CPU IO Wait
    - uid: fly-app-high-iowait
      title: "Fly App - High CPU IO Wait"
      condition: B
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              sum(irate(fly_instance_cpu{mode="iowait"}[5m])) * 100
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: threshold
            refId: B
            expression: A
            conditions:
              - evaluator:
                  params: [20]
                  type: gt
      for: 10m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "High CPU IO wait on {{ $labels.app }}"
        description: "IO wait is {{ $values.A.Value }}%. Disk may be slow."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: warning
        alertname: HighIOWait
        job: fly-app
        team: infrastructure
        service: fly-app

    # 12. App Connect Time Spike
    - uid: fly-app-slow-connect
      title: "Fly App - Slow App Connect Time"
      condition: C
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              histogram_quantile(0.95,
                sum by(le) (
                  rate(fly_app_connect_time_seconds_bucket[5m])
                )
              )
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: reduce
            refId: B
            expression: A
            reducer: last
        - refId: C
          datasourceUid: "-100"
          model:
            type: threshold
            refId: C
            expression: B
            conditions:
              - evaluator:
                  params: [0.5]
                  type: gt
      for: 5m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "Slow connection time to app"
        description: "P95 connect time is {{ $values.A.Value }}s. App may be slow to accept connections."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: warning
        alertname: SlowAppConnect
        job: fly-app
        team: platform
        service: fly-app
