apiVersion: grafana.integreatly.org/v1beta1
kind: GrafanaAlertRuleGroup
metadata:
  name: fly-app-alerts
  namespace: grafana
spec:
  # Reference to your GrafanaInstance
  instanceSelector:
    matchLabels:
      grafana.internal/instance: grafana

  # Folder UID only (no folderTitle in v1beta1)
  folderRef: "external-folder"

  # Alert rule group configuration
  interval: 1m
  name: "Fly App Monitoring"

  rules:
    # 1. High Response Time Alert (>5s)
    - uid: fly-app-response-time
      title: "Fly App - High Response Time (>5s)"
      condition: C

      data:
        - refId: A
          queryType: ""
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              histogram_quantile(0.95,
                sum by(app, status, le) (
                  rate(fly_app_http_response_time_seconds_bucket{app=~"$app"}[5m])
                )
              )
            refId: A
            intervalMs: 1000
            maxDataPoints: 43200

        - refId: B
          queryType: ""
          datasourceUid: "-100"
          model:
            type: reduce
            refId: B
            expression: A
            reducer: last

        - refId: C
          queryType: ""
          datasourceUid: "-100"
          model:
            type: threshold
            refId: C
            expression: B
            conditions:
              - evaluator:
                  params: [5]
                  type: gt

      for: 5m
      noDataState: NoData
      execErrState: Alerting

      annotations:
        summary: "Response time exceeded 5 seconds for {{ $labels.app }}"
        description: "95th percentile response time is {{ $values.A.Value }}s. Consider declaring an incident."
        dashboard: "/d/eiRE4umnz/fly-app"

      labels:
        severity: critical
        team: platform
        service: fly-app

    # 2. HTTP Error Rate Alert
    - uid: fly-app-error-rate
      title: "Fly App - High Error Rate (>5%)"
      condition: D

      data:
        - refId: A
          queryType: ""
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              sum by(app) (
                rate(fly_app_http_responses_count{status=~"5.*", app=~"$app"}[5m])
              )
            refId: A

        - refId: B
          queryType: ""
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              sum by(app) (
                rate(fly_app_http_responses_count{app=~"$app"}[5m])
              )
            refId: B

        - refId: C
          queryType: ""
          datasourceUid: "-100"
          model:
            type: math
            refId: C
            expression: "(A / B) * 100"

        - refId: D
          queryType: ""
          datasourceUid: "-100"
          model:
            type: threshold
            refId: D
            expression: C
            conditions:
              - evaluator:
                  params: [5]
                  type: gt

      for: 5m
      noDataState: NoData
      execErrState: Alerting

      annotations:
        summary: "Error rate above 5% for {{ $labels.app }}"
        description: "HTTP 5xx error rate exceeds threshold. Investigate immediately."
        dashboard: "/d/eiRE4umnz/fly-app"

      labels:
        severity: high
        team: platform
        service: fly-app

    # 3. Memory Pressure Alert
    - uid: fly-app-memory-pressure
      title: "Fly App - High Memory Pressure"
      condition: B

      data:
        - refId: A
          queryType: ""
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              fly_instance_memory_pressure_full{
                app=~"$app",
                pressure_duration="avg60"
              }
            refId: A

        - refId: B
          queryType: ""
          datasourceUid: "-100"
          model:
            type: threshold
            refId: B
            expression: A
            conditions:
              - evaluator:
                  params: [50]
                  type: gt

      for: 10m
      noDataState: NoData
      execErrState: Alerting

      annotations:
        summary: "Memory pressure detected on {{ $labels.app }}"
        description: "Escalate to infrastructure team per SOP."
        dashboard: "/d/eiRE4umnz/fly-app"

      labels:
        severity: high
        team: infrastructure
        service: fly-app

    # 4. Instance Down Alert
    - uid: fly-app-instance-down
      title: "Fly App - Instance Down"
      condition: B

      data:
        - refId: A
          queryType: ""
          relativeTimeRange:
            from: 300
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              fly_instance_up{app=~"$app"}
            refId: A

        - refId: B
          queryType: ""
          datasourceUid: "-100"
          model:
            type: threshold
            refId: B
            expression: A
            conditions:
              - evaluator:
                  params: [1]
                  type: lt

      for: 1m
      noDataState: Alerting
      execErrState: Alerting

      annotations:
        summary: "Instance {{ $labels.instance }} is down"
        description: "Fly.io instance unreachable for {{ $labels.app }}."
        dashboard: "/d/eiRE4umnz/fly-app"

      labels:
        severity: critical
        team: platform
        service: fly-app

    # 5. CPU Throttling Alert
    - uid: fly-app-cpu-throttle
      title: "Fly App - CPU Throttling"
      condition: B

      data:
        - refId: A
          queryType: ""
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              rate(fly_instance_cpu_throttle{app=~"$app"}[5m])
            refId: A

        - refId: B
          queryType: ""
          datasourceUid: "-100"
          model:
            type: threshold
            refId: B
            expression: A
            conditions:
              - evaluator:
                  params: [0]
                  type: gt

      for: 5m
      noDataState: NoData
      execErrState: Alerting

      annotations:
        summary: "CPU throttling on {{ $labels.app }}"
        description: "Consider scaling up resources."
        dashboard: "/d/eiRE4umnz/fly-app"

      labels:
        severity: warning
        team: platform
        service: fly-app

    # 6. Edge Error Rate
    - uid: fly-app-edge-errors
      title: "Fly App - High Edge Error Rate"
      condition: B

      data:
        - refId: A
          queryType: ""
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: fly-io-prometheus
          model:
            expr: |
              sum by(app, region) (
                rate(fly_edge_error_count{app=~"$app"}[5m])
              )
            refId: A

        - refId: B
          queryType: ""
          datasourceUid: "-100"
          model:
            type: threshold
            refId: B
            expression: A
            conditions:
              - evaluator:
                  params: [10]
                  type: gt

      for: 5m
      noDataState: NoData
      execErrState: Alerting

      annotations:
        summary: "Edge errors in {{ $labels.region }}"
        description: "Error rate: {{ $values.A.Value }}/sec in {{ $labels.region }}."
        dashboard: "/d/eiRE4umnz/fly-app"

      labels:
        severity: medium
        team: platform
        service: fly-app
