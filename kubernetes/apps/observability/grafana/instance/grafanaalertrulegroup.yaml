---
apiVersion: grafana.integreatly.org/v1beta1
kind: GrafanaAlertRuleGroup
metadata:
  name: fly-app-alerts
  namespace: observability
spec:
  instanceSelector:
    matchLabels:
      grafana.internal/instance: grafana

  folderRef: "external-folder"
  interval: 1m
  name: "Fly App Monitoring"

  rules:
    # 1. High Response Time Alert
    - uid: fly-app-response-time
      title: "Fly App - High Response Time"
      condition: C
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: prometheus_on_fly
          model:
            expr: |
              histogram_quantile(0.95,
                sum by(app, status, le) (
                  rate(fly_app_http_response_time_seconds_bucket[5m])
                )
              )
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: reduce
            refId: B
            expression: A
            reducer: last
        - refId: C
          datasourceUid: "-100"
          model:
            type: threshold
            refId: C
            expression: B
            conditions:
              - evaluator:
                  params: [5]
                  type: gt
      for: 5m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "Response time exceeded 5 seconds"
        description: "95th percentile response time is too high. Consider declaring an incident."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: critical
        alertname: HighResponseTime
        job: fly-app
        team: platform
        service: fly-app

    # 2. High Error Rate Alert
    - uid: fly-app-error-rate
      title: "Fly App - High Error Rate"
      condition: D
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: prometheus_on_fly
          model:
            expr: |
              sum by(app) (
                rate(fly_app_http_responses_count{status=~"5.*"}[5m])
              )
            refId: A
        - refId: B
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: prometheus_on_fly
          model:
            expr: |
              sum by(app) (
                rate(fly_app_http_responses_count[5m])
              )
            refId: B
        - refId: C
          datasourceUid: "-100"
          model:
            type: math
            refId: C
            expression: "$A / $B * 100"
        - refId: D
          datasourceUid: "-100"
          model:
            type: threshold
            refId: D
            expression: C
            conditions:
              - evaluator:
                  params: [5]
                  type: gt
      for: 5m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "Error rate above 5%"
        description: "HTTP 5xx error rate exceeds threshold. Investigate immediately."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: critical
        alertname: HighErrorRate
        job: fly-app
        team: platform
        service: fly-app

    # 3. Memory Pressure Alert
    - uid: fly-app-memory-pressure
      title: "Fly App - High Memory Pressure"
      condition: C
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: prometheus_on_fly
          model:
            expr: |
              fly_instance_memory_pressure_full{pressure_duration="avg60"}
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: reduce
            refId: B
            expression: A
            reducer: last
        - refId: C
          datasourceUid: "-100"
          model:
            type: threshold
            refId: C
            expression: B
            conditions:
              - evaluator:
                  params: [50]
                  type: gt
      for: 10m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "Memory pressure detected"
        description: "Memory pressure avg60 is high. Escalate to infrastructure team."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: high
        alertname: HighMemoryPressure
        job: fly-app
        team: infrastructure
        service: fly-app

    # 4. Instance Down Alert
    - uid: fly-app-instance-down
      title: "Fly App - Instance Down"
      condition: C
      data:
        - refId: A
          relativeTimeRange:
            from: 300
            to: 0
          datasourceUid: prometheus_on_fly
          model:
            expr: |
              fly_instance_up
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: reduce
            refId: B
            expression: A
            reducer: last
        - refId: C
          datasourceUid: "-100"
          model:
            type: threshold
            refId: C
            expression: B
            conditions:
              - evaluator:
                  params: [1]
                  type: lt
      for: 1m
      noDataState: Alerting
      execErrState: Alerting
      annotations:
        summary: "Instance is down"
        description: "Fly.io instance is unreachable."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: critical
        alertname: InstanceDown
        job: fly-app
        team: platform
        service: fly-app

    # 5. CPU Throttling Alert
    - uid: fly-app-cpu-throttle
      title: "Fly App - CPU Throttling"
      condition: C
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: prometheus_on_fly
          model:
            expr: |
              rate(fly_instance_cpu_throttle[5m])
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: reduce
            refId: B
            expression: A
            reducer: last
        - refId: C
          datasourceUid: "-100"
          model:
            type: threshold
            refId: C
            expression: B
            conditions:
              - evaluator:
                  params: [0]
                  type: gt
      for: 5m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "CPU throttling detected"
        description: "Instance is experiencing CPU throttling. Consider scaling."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: warning
        alertname: CPUThrottling
        job: fly-app
        team: platform
        service: fly-app

    # 6. Edge Error Rate Alert
    - uid: fly-app-edge-errors
      title: "Fly App - High Edge Error Rate"
      condition: C
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: prometheus_on_fly
          model:
            expr: |
              sum by(app, region) (
                rate(fly_edge_error_count[5m])
              )
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: reduce
            refId: B
            expression: A
            reducer: last
        - refId: C
          datasourceUid: "-100"
          model:
            type: threshold
            refId: C
            expression: B
            conditions:
              - evaluator:
                  params: [10]
                  type: gt
      for: 5m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "High edge error rate detected"
        description: "Edge errors exceeding threshold. Check CDN and network."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: medium
        alertname: HighEdgeErrorRate
        job: fly-app
        team: platform
        service: fly-app

    # 7. High 4xx Error Rate
    - uid: fly-app-4xx-rate
      title: "Fly App - High 4xx Error Rate"
      condition: D
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: prometheus_on_fly
          model:
            expr: |
              sum by(app) (
                rate(fly_edge_http_responses_count{status=~"4.*"}[5m])
              )
            refId: A
        - refId: B
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: prometheus_on_fly
          model:
            expr: |
              sum by(app) (
                rate(fly_edge_http_responses_count[5m])
              )
            refId: B
        - refId: C
          datasourceUid: "-100"
          model:
            type: math
            refId: C
            expression: "$A / $B * 100"
        - refId: D
          datasourceUid: "-100"
          model:
            type: threshold
            refId: D
            expression: C
            conditions:
              - evaluator:
                  params: [15]
                  type: gt
      for: 10m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "High 4xx client error rate"
        description: "Client error rate exceeds 15%. Check for invalid requests or API changes."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: warning
        alertname: High4xxRate
        job: fly-app
        team: platform
        service: fly-app

    # 8. TLS Handshake Errors
    - uid: fly-app-tls-errors
      title: "Fly App - TLS Handshake Errors"
      condition: C
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: prometheus_on_fly
          model:
            expr: |
              sum(increase(fly_edge_tls_handshake_errors[5m]))
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: reduce
            refId: B
            expression: A
            reducer: last
        - refId: C
          datasourceUid: "-100"
          model:
            type: threshold
            refId: C
            expression: B
            conditions:
              - evaluator:
                  params: [10]
                  type: gt
      for: 5m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "TLS handshake errors detected"
        description: "Multiple TLS handshake errors in the last 5 minutes. Check certificate validity."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: high
        alertname: TLSHandshakeErrors
        job: fly-app
        team: platform
        service: fly-app

    # 9. High Connection Rate
    - uid: fly-app-high-connections
      title: "Fly App - High Connection Rate"
      condition: C
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: prometheus_on_fly
          model:
            expr: |
              sum(rate(fly_edge_tcp_connects_count[5m]))
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: reduce
            refId: B
            expression: A
            reducer: last
        - refId: C
          datasourceUid: "-100"
          model:
            type: threshold
            refId: C
            expression: B
            conditions:
              - evaluator:
                  params: [1000]
                  type: gt
      for: 5m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "Unusually high connection rate"
        description: "High connection rate detected. Possible traffic spike or DDoS."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: warning
        alertname: HighConnectionRate
        job: fly-app
        team: platform
        service: fly-app

    # 10. Connection Churn
    - uid: fly-app-connection-churn
      title: "Fly App - High Connection Churn"
      condition: D
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: prometheus_on_fly
          model:
            expr: |
              sum(rate(fly_app_tcp_disconnects_count[5m]))
            refId: A
        - refId: B
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: prometheus_on_fly
          model:
            expr: |
              sum(rate(fly_app_tcp_connects_count[5m]))
            refId: B
        - refId: C
          datasourceUid: "-100"
          model:
            type: math
            refId: C
            expression: "$A / $B * 100"
        - refId: D
          datasourceUid: "-100"
          model:
            type: threshold
            refId: D
            expression: C
            conditions:
              - evaluator:
                  params: [80]
                  type: gt
      for: 10m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "High connection churn detected"
        description: "Most connections are short-lived. Check application health."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: medium
        alertname: HighConnectionChurn
        job: fly-app
        team: platform
        service: fly-app

    # 11. High Load Average
    - uid: fly-app-high-load
      title: "Fly App - High Load Average"
      condition: C
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: prometheus_on_fly
          model:
            expr: |
              max(fly_instance_load_average{minutes="1"})
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: reduce
            refId: B
            expression: A
            reducer: last
        - refId: C
          datasourceUid: "-100"
          model:
            type: threshold
            refId: C
            expression: B
            conditions:
              - evaluator:
                  params: [4]
                  type: gt
      for: 5m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "High load average detected"
        description: "1-minute load average is high. CPU may be saturated."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: warning
        alertname: HighLoadAverage
        job: fly-app
        team: platform
        service: fly-app

    # 12. High Network Transfer
    - uid: fly-app-high-network
      title: "Fly App - High Network Transfer"
      condition: C
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: prometheus_on_fly
          model:
            expr: |
              sum(rate(fly_instance_net_sent_bytes{device="eth0"}[5m])) +
              sum(rate(fly_instance_net_recv_bytes{device="eth0"}[5m]))
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: reduce
            refId: B
            expression: A
            reducer: last
        - refId: C
          datasourceUid: "-100"
          model:
            type: threshold
            refId: C
            expression: B
            conditions:
              - evaluator:
                  params: [104857600]
                  type: gt
      for: 10m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "High network traffic detected"
        description: "Network transfer is elevated. Monitor bandwidth costs."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: info
        alertname: HighNetworkTransfer
        job: fly-app
        team: platform
        service: fly-app

    # 13. Low Memory Available
    - uid: fly-app-low-memory
      title: "Fly App - Low Memory Available"
      condition: D
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: prometheus_on_fly
          model:
            expr: |
              avg(fly_instance_memory_mem_available)
            refId: A
        - refId: B
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: prometheus_on_fly
          model:
            expr: |
              avg(fly_instance_memory_mem_total)
            refId: B
        - refId: C
          datasourceUid: "-100"
          model:
            type: math
            refId: C
            expression: "$A / $B * 100"
        - refId: D
          datasourceUid: "-100"
          model:
            type: threshold
            refId: D
            expression: C
            conditions:
              - evaluator:
                  params: [10]
                  type: lt
      for: 5m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "Low available memory"
        description: "Memory available is critically low. Risk of OOM."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: high
        alertname: LowMemoryAvailable
        job: fly-app
        team: infrastructure
        service: fly-app

    # 14. High CPU IO Wait
    - uid: fly-app-high-iowait
      title: "Fly App - High CPU IO Wait"
      condition: C
      data:
        - refId: A
          relativeTimeRange:
            from: 600
            to: 0
          datasourceUid: prometheus_on_fly
          model:
            expr: |
              sum(irate(fly_instance_cpu{mode="iowait"}[5m])) * 100
            refId: A
        - refId: B
          datasourceUid: "-100"
          model:
            type: reduce
            refId: B
            expression: A
            reducer: last
        - refId: C
          datasourceUid: "-100"
          model:
            type: threshold
            refId: C
            expression: B
            conditions:
              - evaluator:
                  params: [20]
                  type: gt
      for: 10m
      noDataState: NoData
      execErrState: Alerting
      annotations:
        summary: "High CPU IO wait detected"
        description: "IO wait is elevated. Disk may be slow."
        dashboard: "/d/eiRE4umnz/fly-app"
      labels:
        severity: warning
        alertname: HighIOWait
        job: fly-app
        team: infrastructure
        service: fly-app
